prob_for_z[i_cluster] <- prob_for_z[i_cluster] * phi_current[i_cluster, i_for_prob_for_z, x[i_sub, i_for_prob_for_z] + 1]
}
}
prob_for_z <- prob_for_z / sum(prob_for_z)
z_new[i_sub] <- which(as.vector(rmultinom(1, 1, prob_for_z) == 1))
}
z_current <- z_new
# save samples
if (i_iter > burnin) {
z[i_iter - burnin, ] <- z_current
phi[i_iter - burnin, , , ] <- phi_current
psi[i_iter - burnin, ] <- psi_current
alphadp[i_iter - burnin] <- alphadp_current
}
}
z_current
library(gtools)
x <- matrix(c(
0, 0, 0,
0, 0, 0,
0, 0, 0,
0, 0, 0,
0, 0, 0,
1, 1, 1,
1, 1, 1,
1, 1, 1,
1, 1, 1,
1, 1, 1
), nrow = 10, byrow = TRUE)
iter <- 1000
burnin <- 5000
right_limit_alphadp <- 6 # uniform prior for alphadp U(0.0001,right_limit_alphadp)
lambdap <- 0.5 # hyperparameter for the prior of phi / Dirichlet distribution
N <- 10 # number of observed subjects
C <- 10 # number of clusters
P <- 3 # number of variables
# iter x N   --> total int(iter) samples of z
z <- matrix(rep(0, iter * N), nrow = iter, ncol = N) # z_i == c_i ,which is the clusters of the subjects
z_current <- matrix(rep(0, N), nrow = 1, ncol = N) # 1 x N   --> current value of z
z_new <- matrix(rep(0, N), nrow = 1, ncol = N) # 1 x N   --> new value of z
no_of_levels <- 2 # number of levels for the variables
# for the StBreaking we sample the whole phi vector
# phi
phi <- array(0, dim = c(iter, C, P, no_of_levels)) # shape: iter x C x P x noOfLevels --> iter x C for (P x noOfLevels) matrices
phi_current <- array(0, dim = c(C, P, no_of_levels)) # shape: C x P x noOfLevels --> C x P for (noOfLevels) matrices
# psi
psi <- array(0, dim = c(iter, C)) # shape: iter x C matrix
psi_current <- matrix(rep(0, C), nrow = 1, ncol = C) # shape: 1 x C matrix
# alpha == 1
alphadp <- rep(1, iter) # 1 for iter times
alphadp_current <- 1
# random group allocation to start
for (i_sub in 1:N) {
# random generation number from 1 to C with equal probability, and assign it to z_current for N times
#      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
# [1,]    5    8    1   10    4   10    6    2    3     4
z_current[i_sub] <- which(as.vector(rmultinom(1, 1, rep(1 / C, C)) == 1))
}
# the standard deviation for the proposal distribution for alphadp
st_dev_for_alphadp_prop <- 0.2
for (i_iter in 2:(iter + burnin)) { # i_iter from 2 to (iter + burnin)
print(i_iter)
# sample \phi
for (i_cluster in 1:C) {
for (ivar in 1:P) {
number_of_successes <- sum(x[z_current == i_cluster, ivar] == 1)
phi_current[i_cluster, ivar, ] <- rdirichlet(1, c(lambdap + number_of_successes, sum(z_current == i_cluster) + lambdap - number_of_successes))
}
}
# sample \psi
for_psi_probs <- sum(z_current == 1)
for (i_psi_probs in 2:C) {
for_psi_probs <- c(for_psi_probs, sum(z_current == i_psi_probs))
}
psi_current <- rdirichlet(1, for_psi_probs + alphadp_current)
# if any of the psi_current is zero, then we add a small number to it
if ((sum(psi_current < (10^(-10)))) > 0) {
sum_of_psi_zero <- sum(psi_current < (10^(-10)))
psi_current[psi_current < (10^(-10))] <- 10^(-10)
psi_current[which(psi_current == max(psi_current))] <- psi_current[which(psi_current == max(psi_current))] - sum_of_psi_zero * (10^(-10))
}
# sample alphadp
alphadp_proposed <- rnorm(1, alphadp_current, st_dev_for_alphadp_prop)
while ((alphadp_proposed < 0.0001) | (alphadp_proposed > right_limit_alphadp)) {
alphadp_proposed <- rnorm(1, alphadp_current, st_dev_for_alphadp_prop)
}
MH_ratio_numerator <- sum(log(psi_current^(alphadp_proposed - 1)))
MH_ratio_denominator <- sum(log(psi_current^(alphadp_current - 1)))
for_truncation_1 <- pnorm(right_limit_alphadp, alphadp_proposed, st_dev_for_alphadp_prop) - pnorm(0.0001, alphadp_proposed, st_dev_for_alphadp_prop)
for_truncation_2 <- pnorm(right_limit_alphadp, alphadp_current, st_dev_for_alphadp_prop) - pnorm(0.0001, alphadp_current, st_dev_for_alphadp_prop)
ratio_of_qproposals_num <- dnorm(alphadp_current, alphadp_proposed, st_dev_for_alphadp_prop) / for_truncation_1
ratio_of_qproposals_den <- dnorm(alphadp_proposed, alphadp_current, st_dev_for_alphadp_prop) / for_truncation_2
ratio_of_qproposals <- ratio_of_qproposals_num / ratio_of_qproposals_den
MH_ratio <- exp(MH_ratio_numerator - MH_ratio_denominator) * ratio_of_qproposals
accept_prob <- min(c(1, MH_ratio))
if (runif(1, 0, 1) < accept_prob) {
alphadp_current <- alphadp_proposed
}
# sample z
for (i_sub in 1:N) {
prob_for_z <- rep(0, C)
for (i_cluster in 1:C) {
prob_for_z[i_cluster] <- psi_current[i_cluster]
for (i_for_prob_for_z in 1:P) {
prob_for_z[i_cluster] <- prob_for_z[i_cluster] * phi_current[i_cluster, i_for_prob_for_z, x[i_sub, i_for_prob_for_z] + 1]
}
}
prob_for_z <- prob_for_z / sum(prob_for_z)
z_new[i_sub] <- which(as.vector(rmultinom(1, 1, prob_for_z) == 1))
}
z_current <- z_new
# save samples
if (i_iter > burnin) {
z[i_iter - burnin, ] <- z_current
phi[i_iter - burnin, , , ] <- phi_current
psi[i_iter - burnin, ] <- psi_current
alphadp[i_iter - burnin] <- alphadp_current
}
}
z_current
z
source("~/.active-rstudio-document", echo=TRUE)
library(class)
# Import all the required packages
library(MASS) # Simulate from a Multivariate Normal Distribution
library(ggplot2)
library(dirichletprocess) # Dirichlet Process
library(dbscan) # Density-based Clustering -- DBSCAN
library(dplyr)
library(class)
# Import all the required packages
library(MASS) # Simulate from a Multivariate Normal Distribution
library(ggplot2)
library(dirichletprocess) # Dirichlet Process
library(dbscan) # Density-based Clustering -- DBSCAN
library(dplyr)
library(class)
ath <- paste(getwd(), '/DC_data/', sep = '')
sa
# Import all the required packages
library(MASS) # Simulate from a Multivariate Normal Distribution
library(ggplot2)
library(dirichletprocess) # Dirichlet Process
library(dbscan) # Density-based Clustering -- DBSCAN
library(dplyr)
library(class)
path <- paste(getwd(), '/DC_data/', sep = '')
getwd()
path <- paste('.', '/DC_data/', sep = '')
if(!file.exists(path)){
dir.create(path)
}
path
path <- paste('/Users/awc789/Library/CloudStorage/OneDrive-UniversityofStAndrews/GitHub/Notebook/R_code', '/DC_data/', sep = '')
if(!file.exists(path)){
dir.create(path)
}
setwd(path)
setwd(path)
getwd()
setwd(path)
getwd()
# Set the path that we needed
path <- paste(getwd(), '/DC_data/', sep = '')
path <- paste('/Users/awc789/Library/CloudStorage/OneDrive-UniversityofStAndrews/GitHub/Notebook/R_code', '/DC_data/', sep = '')
if(!file.exists(path)){
dir.create(path)
}
setwd(path)
# The Synthetic Data Setup
workers_num <- 20   # Have 20 workers
partition <- 50000  # Each distribution generate 50,000 samples in each worker
num <- partition * workers_num  # The total sample number from each distribution (1 million)
miu_matirx <- matrix(c(6, 4, 8, 22.5, 20, 22, 22, 6.5, 1.5, 6, 6, 1.5, 8, 31, 21, 29),
nrow = 2, ncol = 8, byrow=FALSE)
covar_matrix <-array(c(4.84, 0, 0, 2.89, 3.61, 5.05, 5.05, 14.44, 3.61, -5.05,
-5.05, 14.44, 12.25, 0, 0, 3.24, 3.24, 0, 0, 12.25,
14.44, 0, 0, 2.25, 2.25, 0, 0, 17.64, 2.25, 4.2, 4.2, 16),
dim = c(2, 2, 8))
weight_GMM <- c(1/4, 1/4, 1/4, 1/4)
w1 <- c(1/3, 1/3 ,1/3)
w2 <- c(1/2, 1/2)
w3 <- c(1/2, 1/2)
w4 <- c(1)
## Generate the Initial Data
x_1 <- data.frame(mvrnorm(n = num, miu_matirx[,1], covar_matrix[, , 1]))
x_6 <- data.frame(mvrnorm(n = num, miu_matirx[,2], covar_matrix[, , 2]))
x_4 <- data.frame(mvrnorm(n = num, miu_matirx[,3], covar_matrix[, , 3]))
x_8 <- data.frame(mvrnorm(n = num, miu_matirx[,4], covar_matrix[, , 4]))
x_2 <- data.frame(mvrnorm(n = num, miu_matirx[,5], covar_matrix[, , 5]))
x_3 <- data.frame(mvrnorm(n = num, miu_matirx[,6], covar_matrix[, , 6]))
x_7 <- data.frame(mvrnorm(n = num, miu_matirx[,7], covar_matrix[, , 7]))
x_5 <- data.frame(mvrnorm(n = num, miu_matirx[,8], covar_matrix[, , 8]))
## Give Data lables
x_1$component = rep(1,num)
x_2$component = rep(1,num)
x_3$component = rep(1,num)
x_4$component = rep(4,num)
x_5$component = rep(4,num)
x_6$component = rep(8,num)
x_7$component = rep(8,num)
x_8$component = rep(12,num)
## Give Data sub_lables
x_1$subcomponent = rep(1,num)
x_2$subcomponent = rep(2,num)
x_3$subcomponent = rep(3,num)
x_4$subcomponent = rep(4,num)
x_5$subcomponent = rep(5,num)
x_6$subcomponent = rep(6,num)
x_7$subcomponent = rep(7,num)
x_8$subcomponent = rep(8,num)
GMM_1 <- w1[1] * x_1 + w1[2] * x_2 + w1[3] * x_3
GMM_2 <- w2[1] * x_4 + w2[2] * x_5
GMM_3 <- w3[1] * x_6 + w3[2] * x_7
GMM_4 <- w4[1] * x_8
Mixture_GMM <- weight_GMM[1] * GMM_1 + weight_GMM[2] * GMM_2 + weight_GMM[3] * GMM_3 + weight_GMM[4] * GMM_4
num_sample <- 500 # the number of date used for ploting
x_mix <- rbind(x_1[1:num_sample,], x_2[1:num_sample,])
x_mix <- rbind(x_mix, x_3[1:num_sample,])
x_mix <- rbind(x_mix, x_4[1:num_sample,])
x_mix <- rbind(x_mix, x_5[1:num_sample,])
x_mix <- rbind(x_mix, x_6[1:num_sample,])
x_mix <- rbind(x_mix, x_7[1:num_sample,])
x_mix <- rbind(x_mix, x_8[1:num_sample,])
ggplot(x_mix, aes(x = X1, y = X2, colour = component)) +
geom_point(size=3)
GMM_mix <- rbind(GMM_1[1:num_sample,], GMM_2[1:num_sample,])
GMM_mix <- rbind(GMM_mix, GMM_3[1:num_sample,])
GMM_mix <- rbind(GMM_mix, GMM_4[1:num_sample,])
ggplot(GMM_mix, aes(x = X1, y = X2, colour = component)) +
geom_point(size=3)
Mixture_GMM$component = rep(-10,num)
x_mix_with_GMM <- rbind(x_mix, Mixture_GMM[1:num_sample,])
ggplot(x_mix_with_GMM, aes(x = X1, y = X2, colour = component)) +
geom_point(size=3)
write.table(x_1, file = paste(path, "x_1_total.txt", sep=''), sep = ",")
write.table(x_2, file = paste(path, "x_2_total.txt", sep=''), sep = ",")
write.table(x_3, file = paste(path, "x_3_total.txt", sep=''), sep = ",")
write.table(x_4, file = paste(path, "x_4_total.txt", sep=''), sep = ",")
write.table(x_5, file = paste(path, "x_5_total.txt", sep=''), sep = ",")
write.table(x_6, file = paste(path, "x_6_total.txt", sep=''), sep = ",")
write.table(x_7, file = paste(path, "x_7_total.txt", sep=''), sep = ",")
write.table(x_8, file = paste(path, "x_8_total.txt", sep=''), sep = ",")
write.table(Mixture_GMM, file = paste(path, "Mixture_GMM_total.txt", sep=''), sep = ",")
name_x <- paste("x_", 1:8, sep = "")
name_workers <- paste("worker_", 1:20, sep = "")
count <- 0
for(i in list(x_1, x_2, x_3, x_4, x_5, x_6, x_7, x_8)){
count <- count +1
current_x <- name_x[count]
# For the workers
for(k in rep(1:workers_num)){
current_worker <- name_workers[k]
folder <- paste(path, '/', current_worker, sep = "")
# check the folder
if(!file.exists(folder)){
dir.create(folder)
}
# for each workers
start_loop <- partition * (k-1) + 1
end_loop <- partition * k
temp <- i[start_loop:end_loop,]
f <- paste(path, current_worker, '/', current_x, '_', current_worker, '.txt', sep = "")
write.table(temp, file = f, sep = ",")
}
}
for(k in rep(1:workers_num)){
current_worker <- name_workers[k]
folder <- paste(path, '/', current_worker, sep = "")
# for each workers
start_loop <- partition * (k-1) + 1
end_loop <- partition * k
temp <- i[start_loop:end_loop,]
f <- paste(path, current_worker, '/', 'Mixture_GMM_', current_worker, '.txt', sep = "")
write.table(temp, file = f, sep = ",")
}
name_x <- paste("x_", 1:8, sep = "")
name_workers <- paste("worker_", 1:20, sep = "")
# By change the value of these 2 parameters smaller, it can reduce the computational time
num_dp <- 2400    # The number of subsamping for DP clustering
MCMC_mum <- 1500  # The number of samples obtained during MCMC
## The parameters below are just for a quick presentation.
name_workers <- paste("worker_", 1:1, sep = "")
num_dp <- 2000
MCMC_mum <- 1000
for(current_worker in name_workers){
data <- data.frame()
for (current_x in name_x) {
f <- paste(path, current_worker, '/', current_x, '_', current_worker, '.txt', sep = "")
data_temp <- read.table(f, sep = ',', header = TRUE)
data <- rbind(data, data_temp)
}
# --------------------------------------------
# DP for the clustering
data <- data[sample(1:nrow(data)),]
data_dp <- data[1:num_dp,]
data_dp <- matrix(c(data_dp$X1, data_dp$X2), ncol = 2, byrow = FALSE)
dpCluster <-  DirichletProcessMvnormal(data_dp)
dpCluster <- Fit(dpCluster, MCMC_mum, progressBar = FALSE)
plot(dpCluster)
data_dp_cluster <- data[1:num_dp,]
data_dp_cluster$clusterLabels <- dpCluster$clusterLabels
label_result <- t(data.frame(table(dpCluster$clusterLabels)))
drop_clusterlabels <- c()
for (i in seq(ncol(label_result))) {
if(label_result[2,i] <= (nrow(data_dp_cluster)/ncol(label_result))){
drop_clusterlabels <- append(drop_clusterlabels, i)
data_dp_cluster <- data_dp_cluster[data_dp_cluster$clusterLabels != i,]
}
}
remain_clusterlabels <- data.frame(table(data_dp_cluster$clusterLabels))
center_point <- data.frame(X1 = c(1:nrow(remain_clusterlabels)),
X2 = c(1:nrow(remain_clusterlabels)),
clusterlabels = c(1:nrow(remain_clusterlabels)))
remain_clusterlabels <- remain_clusterlabels$Var1
for(i in remain_clusterlabels){
i <- as.numeric(i)
temp_X1 <- data_dp_cluster[data_dp_cluster$clusterLabels == i,]$X1
temp_X2 <- data_dp_cluster[data_dp_cluster$clusterLabels == i,]$X2
center_point[i,1] <- mean(temp_X1)
center_point[i,2] <- mean(temp_X2)
center_point[i,3] <- i
}
folder <- paste(path, '/Center_point/', sep = "")
# check the folder
if(!file.exists(folder)){
dir.create(folder)
}
f <- paste(path, 'Center_point/Center_point_', current_worker, '.txt', sep = "")
write.table(center_point, file = f, sep = ",")
}
## The parameters below are just for a quick presentation.
name_workers <- paste("worker_", 1:1, sep = "")
num_dp <- 200
MCMC_mum <- 20
for(current_worker in name_workers){
data <- data.frame()
for (current_x in name_x) {
f <- paste(path, current_worker, '/', current_x, '_', current_worker, '.txt', sep = "")
data_temp <- read.table(f, sep = ',', header = TRUE)
data <- rbind(data, data_temp)
}
# --------------------------------------------
# DP for the clustering
data <- data[sample(1:nrow(data)),]
data_dp <- data[1:num_dp,]
data_dp <- matrix(c(data_dp$X1, data_dp$X2), ncol = 2, byrow = FALSE)
dpCluster <-  DirichletProcessMvnormal(data_dp)
dpCluster <- Fit(dpCluster, MCMC_mum, progressBar = FALSE)
plot(dpCluster)
data_dp_cluster <- data[1:num_dp,]
data_dp_cluster$clusterLabels <- dpCluster$clusterLabels
label_result <- t(data.frame(table(dpCluster$clusterLabels)))
drop_clusterlabels <- c()
for (i in seq(ncol(label_result))) {
if(label_result[2,i] <= (nrow(data_dp_cluster)/ncol(label_result))){
drop_clusterlabels <- append(drop_clusterlabels, i)
data_dp_cluster <- data_dp_cluster[data_dp_cluster$clusterLabels != i,]
}
}
remain_clusterlabels <- data.frame(table(data_dp_cluster$clusterLabels))
center_point <- data.frame(X1 = c(1:nrow(remain_clusterlabels)),
X2 = c(1:nrow(remain_clusterlabels)),
clusterlabels = c(1:nrow(remain_clusterlabels)))
remain_clusterlabels <- remain_clusterlabels$Var1
for(i in remain_clusterlabels){
i <- as.numeric(i)
temp_X1 <- data_dp_cluster[data_dp_cluster$clusterLabels == i,]$X1
temp_X2 <- data_dp_cluster[data_dp_cluster$clusterLabels == i,]$X2
center_point[i,1] <- mean(temp_X1)
center_point[i,2] <- mean(temp_X2)
center_point[i,3] <- i
}
folder <- paste(path, '/Center_point/', sep = "")
# check the folder
if(!file.exists(folder)){
dir.create(folder)
}
f <- paste(path, 'Center_point/Center_point_', current_worker, '.txt', sep = "")
write.table(center_point, file = f, sep = ",")
}
plot(dpCluster)
name_x <- paste("x_", 1:8, sep = "")
name_workers <- paste("worker_", 1:20, sep = "")
name_x <- paste("x_", 1:8, sep = "")
name_workers <- paste("worker_", 1:20, sep = "")
data <- data.frame()
for(current_worker in name_workers){
f <- paste(path, 'Center_point/Center_point_', current_worker, '.txt', sep = "")
data_temp <- read.table(f, sep = ',', header = TRUE)
data <- rbind(data, data_temp)
}
## The parameters below are just for a quick presentation.
name_workers <- paste("worker_", 1:20, sep = "")
#num_dp <- 2000
#MCMC_mum <- 1000
num_dp <- 200
MCMC_mum <- 20
for(current_worker in name_workers){
data <- data.frame()
for (current_x in name_x) {
f <- paste(path, current_worker, '/', current_x, '_', current_worker, '.txt', sep = "")
data_temp <- read.table(f, sep = ',', header = TRUE)
data <- rbind(data, data_temp)
}
# --------------------------------------------
# DP for the clustering
data <- data[sample(1:nrow(data)),]
data_dp <- data[1:num_dp,]
data_dp <- matrix(c(data_dp$X1, data_dp$X2), ncol = 2, byrow = FALSE)
dpCluster <-  DirichletProcessMvnormal(data_dp)
dpCluster <- Fit(dpCluster, MCMC_mum, progressBar = FALSE)
plot(dpCluster)
data_dp_cluster <- data[1:num_dp,]
data_dp_cluster$clusterLabels <- dpCluster$clusterLabels
label_result <- t(data.frame(table(dpCluster$clusterLabels)))
drop_clusterlabels <- c()
for (i in seq(ncol(label_result))) {
if(label_result[2,i] <= (nrow(data_dp_cluster)/ncol(label_result))){
drop_clusterlabels <- append(drop_clusterlabels, i)
data_dp_cluster <- data_dp_cluster[data_dp_cluster$clusterLabels != i,]
}
}
remain_clusterlabels <- data.frame(table(data_dp_cluster$clusterLabels))
center_point <- data.frame(X1 = c(1:nrow(remain_clusterlabels)),
X2 = c(1:nrow(remain_clusterlabels)),
clusterlabels = c(1:nrow(remain_clusterlabels)))
remain_clusterlabels <- remain_clusterlabels$Var1
for(i in remain_clusterlabels){
i <- as.numeric(i)
temp_X1 <- data_dp_cluster[data_dp_cluster$clusterLabels == i,]$X1
temp_X2 <- data_dp_cluster[data_dp_cluster$clusterLabels == i,]$X2
center_point[i,1] <- mean(temp_X1)
center_point[i,2] <- mean(temp_X2)
center_point[i,3] <- i
}
folder <- paste(path, '/Center_point/', sep = "")
# check the folder
if(!file.exists(folder)){
dir.create(folder)
}
f <- paste(path, 'Center_point/Center_point_', current_worker, '.txt', sep = "")
write.table(center_point, file = f, sep = ",")
}
plot(dpCluster)
name_x <- paste("x_", 1:8, sep = "")
name_workers <- paste("worker_", 1:20, sep = "")
data <- data.frame()
for(current_worker in name_workers){
f <- paste(path, 'Center_point/Center_point_', current_worker, '.txt', sep = "")
data_temp <- read.table(f, sep = ',', header = TRUE)
data <- rbind(data, data_temp)
}
ggplot(data, aes(x = X1, y = X2, colour = clusterlabels)) +
geom_point(size=3)
data <- data.frame()
for(current_worker in name_workers){
f <- paste(path, 'Center_point/Center_point_', current_worker, '.txt', sep = "")
data_temp <- read.table(f, sep = ',', header = TRUE)
data <- rbind(data, data_temp)
}
ggplot(data, aes(x = X1, y = X2, colour = clusterlabels)) +
geom_point(size=3)
data_central <- matrix(c(data$X1, data$X2), ncol = 2, byrow = FALSE)
db = dbscan(data_central, 5, 4)
hullplot(data_central, db$cluster)
data$clusterlabels <- db$cluster
ggplot(data, aes(x = X1, y = X2, colour = clusterlabels)) +
geom_point(size=3)
# ---------------------------------------------------------------------------------------------
center_point <- data.frame(X1 = c(1:nrow(data.frame(table(data$clusterlabels)))),
X2 = c(1:nrow(data.frame(table(data$clusterlabels)))),
clusterlabels = c(1:nrow(data.frame(table(data$clusterlabels)))))
for(i in data.frame(table(data$clusterlabels))$Var1){
i <- as.numeric(i)
temp_X1 <- data[data$clusterlabels == i,]$X1
temp_X2 <- data[data$clusterlabels == i,]$X2
center_point[i,1] <- mean(temp_X1)
center_point[i,2] <- mean(temp_X2)
center_point[i,3] <- i
}
# This is the function of master clustering
master_clustering <- function(data, center){
data_result <- data.frame()
for(i in seq(nrow(data))){
X1 <- data[i,]$X1
X2 <- data[i,]$X2
data_result[i,1] <- X1
data_result[i,2] <- X2
for(j in seq(nrow(center))){
distance <- sqrt((X1 - center[j,]$X1)^2 + (X2 - center[j,]$X2)^2)
data_result[i,j+2] <- distance
}
}
k <- ncol(data_result)
distace_name <- c(1:(k-2))
colnames(data_result) <- c('X1', 'X2', distace_name)
data_result$clusterlabels <- colnames(data_result[,3:k])[apply(data_result[,3:k],1,which.min)]
return(data_result)
}
data_master <- data.frame()
for(current_x in name_x){
f <- paste(path, current_x, '_total.txt', sep = "")
data_temp <- read.table(f, sep = ',', header = TRUE)
data_master <- rbind(data_master, data_temp)
}
sample_size <- 8000
data_master <- data_master[sample(1:nrow(data_master)), ]
data_master_sample <- data_master[1:sample_size, ]
master_result <- master_clustering(data_master_sample, center_point)
ggplot(master_result, aes(x = X1, y = X2, colour = clusterlabels)) +
geom_point(size=3)
